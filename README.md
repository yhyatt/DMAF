<p align="center">
  <img src="assets/dmaf-logo.svg" alt="DMAF Logo" width="200"/>
</p>

<h1 align="center">ğŸ¦ DMAF</h1>
<h3 align="center">Don't Miss A Face</h3>

<p align="center">
  <strong>Automated WhatsApp photo & video backup with intelligent face recognition</strong>
</p>

<p align="center">
  Never miss a moment with your loved ones â€” DMAF watches your WhatsApp groups,<br/>
  recognizes the faces you care about in photos <em>and videos</em>, and backs them up to Google Photos automatically.<br/>
  <strong>Set it up once. After that: zero LLM tokens, minimal cloud costs, fully autonomous.</strong>
</p>

<p align="center">
  <a href="https://github.com/yhyatt/DMAF/actions/workflows/ci.yml">
    <img src="https://img.shields.io/github/actions/workflow/status/yhyatt/DMAF/ci.yml?branch=main&style=for-the-badge&logo=github&label=CI" alt="CI Status"/>
  </a>
  <a href="https://github.com/yhyatt/DMAF/blob/main/LICENSE">
    <img src="https://img.shields.io/github/license/yhyatt/DMAF?style=for-the-badge" alt="License"/>
  </a>
  <a href="https://github.com/yhyatt/DMAF">
    <img src="https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python&logoColor=white" alt="Python Version"/>
  </a>
</p>

<p align="center">
  <a href="https://github.com/yhyatt/DMAF/stargazers">
    <img src="https://img.shields.io/github/stars/yhyatt/DMAF?style=for-the-badge&logo=github" alt="GitHub Stars"/>
  </a>
  <a href="https://github.com/yhyatt/DMAF/issues">
    <img src="https://img.shields.io/github/issues/yhyatt/DMAF?style=for-the-badge&logo=github" alt="GitHub Issues"/>
  </a>
  <a href="https://github.com/yhyatt/DMAF/commits/main">
    <img src="https://img.shields.io/github/last-commit/yhyatt/DMAF?style=for-the-badge&logo=git&logoColor=white" alt="Last Commit"/>
  </a>
</p>

<p align="center">
  <a href="#-openclaw-friendly">OpenClaw ğŸ¦</a> â€¢
  <a href="#-features">Features</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-how-it-works">How It Works</a> â€¢
  <a href="#%EF%B8%8F-configuration">Configuration</a> â€¢
  <a href="#-face-recognition-backends">Backends</a> â€¢
  <a href="#-contributing">Contributing</a>
</p>

---

## ğŸ¦ OpenClaw Friendly

DMAF is designed to be set up and operated entirely by an AI agent. If you use [OpenClaw](https://openclaw.ai), you can go from zero to a working pipeline with a single prompt.

**Install the DMAF skill** from [ClaWHub](https://clawhub.com/skills/dmaf) (or copy [`deploy/openclaw-skill/`](deploy/openclaw-skill/) to your skills directory), then just say:

> *"Set up DMAF for me. My GCP project ID is `[your-project]` and my WhatsApp is already connected to OpenClaw."*

Your agent will walk through the full setup: GCP project, service account, GCS buckets, reference photos, config, the media sync cron, and the Cloud Scheduler â€” reading [`deploy/setup-secrets.md`](deploy/setup-secrets.md) as its guide.

> ğŸ’¡ **After setup: zero LLM tokens.** The ongoing pipeline is a system cron + Cloud Run job â€” pure infrastructure, no AI calls, no ongoing API cost.

**Also friendly for:**
- ğŸ¤– **Coding agents** (Claude Code, Copilot, Cursor) â€” [`AGENTS.md`](AGENTS.md) gives full architecture context, test patterns, and common pitfalls
- ğŸ¦¾ **MCP clients** (Claude Desktop, Claude Code, Cursor, Windsurf) â€” install the [MCP server](deploy/mcp-setup.md) and your AI can `trigger_scan()`, `get_status()`, `add_person()` and more â€” no gcloud knowledge needed

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ” Smart Face Recognition
- **Three powerful backends**: `dlib` (CPU-optimized), `InsightFace` (non-commercial), or `AuraFace` (Apache 2.0, **commercial use OK**)
- **Photos & video clips**: Scans both images and WhatsApp video clips â€” stops on first match, uploads the full clip
- **Multi-face detection**: Handles group photos and videos with multiple faces
- **Configurable tolerance**: Fine-tune matching sensitivity per deployment
- **Advanced detection thresholds**: Separate thresholds for training vs. production

</td>
<td width="50%">

### ğŸ¦ OpenClaw Friendly
- **One-prompt setup**: Install the DMAF skill, describe your setup, done
- **WhatsApp media capture**: OpenClaw intercepts group photos & videos automatically â€” no desktop app, no Android required
- **Token-free after setup**: The sync cron and Cloud Run pipeline run with zero LLM calls â€” only minimal GCP infrastructure costs (Cloud Run + GCS, free-tier eligible)
- **Zero-maintenance sync**: System cron uploads media to GCS every 30 min, no agent involvement
- **Agent-operable**: Trigger scans, view logs, add people â€” all via shell/gcloud commands any agent can run
- ğŸ¤– **Developer friendly**: `AGENTS.md` with architecture, mocks, pitfalls, CI rules
- ğŸ¦¾ **Agentic friendly**: API-first pipeline, gcloud-scriptable end to end

</td>
</tr>
<tr>
<td width="50%">

### ğŸ”„ Auto-Refresh Training
- **Intelligent updates**: Automatically adds high-quality matched frames to known_people every 60 days
- **Smart selection**: Picks moderately challenging images (score â‰ˆ 0.65) for best training signal
- **Face cropping**: Extracts and saves padded face crops
- **Email notifications**: Get notified when training images are added

</td>
<td width="50%">

### â˜ï¸ Google Photos Integration
- **Automatic uploads**: Photos and full video clips backed up seamlessly
- **Album organization**: Optionally organize into a named album
- **OAuth2 authentication**: Secure, offline token-based access
- **Cloud staging support**: Delete source files after upload (ideal for GCS pipelines)

</td>
</tr>
<tr>
<td width="50%">

### âš¡ Efficient & Token-Free
- **Zero LLM tokens after setup**: The entire pipeline â€” sync cron, face recognition, upload â€” runs without any AI calls
- **SHA256 deduplication**: Never process the same file twice â€” survives container restarts via Firestore
- **Video early exit**: Sampling stops the moment a known face is found â€” no wasted compute
- **Intelligent retry logic**: Exponential backoff for network resilience
- **Scale-to-zero**: Cloud Run Job â€” no cost when idle, GCP free tier eligible

</td>
<td width="50%">

### ğŸ“§ Observability & Monitoring
- **Email alerts**: SMTP notifications for errors and borderline recognitions
- **Score tracking**: Records similarity scores (0.0â€“1.0) for every match
- **Configurable timezone**: Alert emails show timestamps in your local time (IANA timezone)
- **Batched notifications**: Hourly digest prevents inbox spam
- **Event retention**: 90-day history with automatic cleanup

</td>
</tr>
</table>

---

## ğŸš€ Quick Start

### ğŸ¦ Have OpenClaw? One prompt away

1. Install the DMAF skill from [ClaWHub](https://clawhub.com/skills/dmaf), or copy [`deploy/openclaw-skill/`](deploy/openclaw-skill/) to `~/.openclaw/skills/dmaf/`
2. Make sure your WhatsApp channel is linked in OpenClaw
3. Say to your agent:

```
Set up DMAF for me. My GCP project ID is [your-project-id] and my WhatsApp 
is already connected to OpenClaw. Walk me through everything.
```

Your agent reads [`deploy/setup-secrets.md`](deploy/setup-secrets.md) and [`deploy/openclaw-integration.md`](deploy/openclaw-integration.md) to guide you step by step.

> âœ… **Zero ongoing tokens.** Once setup is done, DMAF runs entirely on a system cron + Cloud Run â€” no LLM involved, no AI API costs â€” only the minimal GCP infrastructure you already pay for.

---

### ğŸ› ï¸ Manual Setup

#### Prerequisites

- Python 3.10 or higher
- Google Cloud project with Photos Library API enabled
- WhatsApp media access via one of:
  - **[OpenClaw](https://openclaw.ai) integration** (iPhone/Android) â€” â­ Recommended, see [`deploy/openclaw-integration.md`](deploy/openclaw-integration.md)
  - **WhatsApp Desktop + rclone** â€” Cross-platform
  - **Android direct sync** â€” FolderSync Pro, Syncthing

#### Installation

```bash
git clone https://github.com/yhyatt/DMAF.git
cd DMAF

python -m venv .venv && source .venv/bin/activate

# Choose your face recognition backend:
pip install -e ".[auraface]"       # â­ Apache 2.0 â€” commercial OK, zero false positives
pip install -e ".[insightface]"    # High accuracy, non-commercial only
pip install -e ".[face-recognition]"  # CPU-optimized, easiest setup
```

#### Setup

1. **Add reference photos** of the people to recognize:
   ```
   data/known_people/
   â”œâ”€â”€ Alice/
   â”‚   â”œâ”€â”€ photo1.jpg
   â”‚   â””â”€â”€ photo2.jpg
   â””â”€â”€ Bob/
       â””â”€â”€ photo1.jpg
   ```

2. **Configure:**
   ```bash
   cp config.example.yaml config.yaml
   # Edit config.yaml â€” set watch_dirs and recognition backend
   ```

3. **Run:**
   ```bash
   dmaf --config config.yaml
   # Or: python -m dmaf --config config.yaml
   ```

4. **Cloud deployment** (GCS + Cloud Run, runs on a schedule, scales to zero):
   â†’ Follow [`deploy/setup-secrets.md`](deploy/setup-secrets.md)

---

## ğŸ”„ How It Works

```mermaid
graph LR
    A[ğŸ“± WhatsApp Groups] -->|OpenClaw captures| B[ğŸ’¾ GCS Staging Bucket]
    B -->|Cloud Scheduler hourly| C[â˜ï¸ Cloud Run Job]
    C --> D{ğŸ” Face Found?}
    D -->|Yes â€” photo or video| E[ğŸ“¸ Upload to Google Photos]
    D -->|No match| F[â­ï¸ Skip]
    E --> G[ğŸ—„ï¸ Firestore Dedup]
    F --> G
    G -->|SHA256| H[ğŸš« Never Reprocess]
```

1. **Capture** â€” OpenClaw intercepts WhatsApp group media and saves it locally; a system cron (zero LLM tokens) uploads it to GCS every 30 min
2. **Schedule** â€” Cloud Scheduler triggers the Cloud Run job hourly â€” no agent, no AI cost
3. **Load** â€” Reference photos downloaded from GCS bucket at job startup
4. **Detect** â€” Each file is scanned: images once, videos sampled at 1â€“2fps with early exit on first match
5. **Upload** â€” Matched photos and full video clips are uploaded to Google Photos
6. **Deduplicate** â€” SHA256 hash stored in Firestore; the same file is never processed twice

---

## âš™ï¸ Configuration

```yaml
watch_dirs:
  - "gs://your-project-whatsapp-media/"   # GCS staging bucket (cloud)
  - "/path/to/WhatsApp/Images"            # Local directory (dev)

known_people_gcs_uri: "gs://your-project-known-people"

recognition:
  backend: "auraface"      # auraface | insightface | face_recognition
  tolerance: 0.5           # 0.0 (strictest) â†’ 1.0 (loosest)
  min_face_size_pixels: 20

google_photos_album_name: "Family â€” Auto WhatsApp"

alerting:
  enabled: true
  timezone: "America/New_York"   # IANA name â€” used in alert email timestamps
  recipients: ["you@example.com"]
```

Full annotated template: [`config.example.yaml`](config.example.yaml) | Cloud template: [`config.cloud.example.yaml`](config.cloud.example.yaml)

---

## ğŸ§  Face Recognition Backends

| Feature | AuraFace â­ | InsightFace | face_recognition (dlib) |
|---------|------------|-------------|-------------------------|
| **License** | âœ… Apache 2.0 (commercial OK) | âš ï¸ Non-commercial | MIT |
| **False Positive Rate** | âœ… **0.0%** ğŸ›¡ï¸ | 1.87% | ~11% âš ï¸ |
| **Accuracy (TPR)** | 80â€“85% | 82.5% | 92.5% |
| **Speed** | âš¡ Fast (12Ã— vs dlib) | âš¡ Fastest | ğŸ¢ Slow |
| **GPU Support** | âœ… CUDA | âœ… CUDA | âŒ CPU only |
| **Best For** | ğŸ† Production | Research | Development |

**Use AuraFace** for production â€” zero false positives means zero privacy violations. Commercial license, no restrictions.

### ğŸ”Œ Extensible Architecture

Adding a new backend is simple:
```python
# src/dmaf/face_recognition/your_backend.py
def load_known_faces(known_root: str, **params): ...
def best_match(known_faces, test_image, **params): ...
```
Register in `factory.py` and you're done. See existing backends for examples.

---

## ğŸ“ Project Structure

```
DMAF/
â”œâ”€â”€ src/dmaf/
â”‚   â”œâ”€â”€ __main__.py           # CLI entrypoint + Uploader (on_match / on_match_video)
â”‚   â”œâ”€â”€ config.py             # Pydantic settings â€” all fields with defaults + docs
â”‚   â”œâ”€â”€ watcher.py            # Core scan loop + file processing helpers
â”‚   â”œâ”€â”€ video_processor.py    # iter_frames generator, find_face_in_video (early exit)
â”‚   â”œâ”€â”€ gcs_watcher.py        # GCS helpers: list, download, cleanup
â”‚   â”œâ”€â”€ database.py           # SQLite (local) + Firestore (cloud) dedup backends
â”‚   â”œâ”€â”€ known_refresh.py      # Auto-refresh training images
â”‚   â”œâ”€â”€ alerting/             # Email alert batching and templates
â”‚   â””â”€â”€ face_recognition/     # Backend factory: AuraFace, InsightFace, dlib
â”œâ”€â”€ deploy/
â”‚   â”œâ”€â”€ setup-secrets.md      # ğŸ”‘ All credentials setup, start here
â”‚   â”œâ”€â”€ openclaw-integration.md  # ğŸ¦ OpenClaw media sync guide
â”‚   â”œâ”€â”€ openclaw-skill/       # ğŸ¦ Installable OpenClaw skill (ClaWHub)
â”‚   â”œâ”€â”€ mcp-setup.md          # ğŸ”Œ MCP server setup (Claude Desktop / Code / Cursor)
â”‚   â””â”€â”€ README.md             # GCP deployment walkthrough
â”œâ”€â”€ tests/                    # pytest â€” mirrors src/dmaf structure
â”œâ”€â”€ AGENTS.md                 # ğŸ¤– Coding agent guide (Claude, Copilot, Cursor)
â”œâ”€â”€ config.example.yaml       # Annotated config template (local dev)
â””â”€â”€ config.cloud.example.yaml # Annotated config template (cloud deployment)
```

---

## ğŸ› ï¸ Development

```bash
pip install -e ".[dev,all]"
pre-commit install          # ruff + mypy before every commit

pytest tests/ -v            # Run tests
mypy src/dmaf               # Type check
ruff check src/ tests/      # Lint
```

See [`AGENTS.md`](AGENTS.md) for architecture decisions, mock patterns, and CI rules.

---

## ğŸ—ºï¸ Roadmap

- [x] **Phase A**: Core bug fixes (RGB/BGR, caching, retry logic) âœ…
- [x] **Phase B**: Project restructuring (src layout, Pydantic) âœ…
- [x] **Phase C**: Unit tests (286 tests, 75%+ coverage) âœ…
- [x] **Phase D**: Face recognition benchmarking & LOOCV validation âœ…
- [x] **Phase D+**: Advanced detection tuning & FPR analysis âœ…
- [x] **Phase E**: CI/CD (GitHub Actions, automated testing) âœ…
- [x] **Phase F-prep**: Observability & auto-refresh (alerts, score tracking, AuraFace) âœ…
- [x] **Phase F**: Cloud deployment (GCS + Cloud Run + Firestore) âœ…
- [x] **Phase G**: Documentation, OpenClaw skill, open-source ready âœ…

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- [AuraFace](https://huggingface.co/fal/AuraFace-v1) â€” Apache 2.0 face recognition model
- [InsightFace](https://github.com/deepinsight/insightface) â€” Deep learning face analysis
- [face_recognition](https://github.com/ageitgey/face_recognition) â€” dlib-based recognition
- [OpenClaw](https://openclaw.ai) â€” AI agent platform with WhatsApp integration
- [Google Photos Library API](https://developers.google.com/photos/library/guides/get-started)
- [Watchdog](https://github.com/gorakhargosh/watchdog) â€” File system monitoring

---

<p align="center">
  <sub>Made with ğŸ¦€ by <a href="https://github.com/yhyatt">yhyatt</a></sub>
</p>

<p align="center">
  <a href="https://github.com/yhyatt/DMAF">
    <img src="https://img.shields.io/badge/ğŸ¦_Star_this_repo-If_it_helped_you!-yellow?style=for-the-badge" alt="Star this repo"/>
  </a>
</p>
